# ğŸ“š PDF Q&A Chatbot with RAG

An intelligent document question-answering system built with **Retrieval-Augmented Generation (RAG)** architecture. Upload your documents and chat with them using AI!

[![Deploy to HuggingFace Spaces](https://huggingface.co/datasets/huggingface/badges/raw/main/deploy-to-spaces-md.svg)](https://huggingface.co/spaces)

## âœ¨ What it does

- **Upload documents** (PDF, TXT, DOCX) and ask questions about their content
- **Smart retrieval** using vector search to find relevant document sections  
- **Dual AI setup**: Local privacy (Ollama) + Cloud deployment (HuggingFace)
- **Professional vector storage** with Qdrant Cloud

## ğŸ› ï¸ Tech Stack

- **Frontend**: Streamlit with custom UI
- **Vector Database**: Qdrant Cloud (persistent storage)
- **AI Models**: 
  - ğŸ  **Local**: Ollama/Mistral (private, offline)
  - â˜ï¸ **Production**: HuggingFace FLAN-T5 (free, cloud)
- **Framework**: LangChain for RAG pipeline

## ğŸš€ Deployment Options

### ğŸ¤— HuggingFace Spaces (Recommended)

**Automatic deployment from this GitHub repo:**

1. **Fork this repository**
2. **Create HF Space** and connect to your forked repo
3. **Add secrets** in Space settings:
   ```
   QDRANT_URL=your_qdrant_cloud_url
   QDRANT_API_KEY=your_api_key
   ```
4. **Auto-sync**: Push to GitHub â†’ Automatically deploys to HF Spaces!

### â˜ï¸ Streamlit Community Cloud

1. **Connect this GitHub repo** to Streamlit Cloud
2. **Add secrets** in app settings:
   ```
   QDRANT_URL=your_qdrant_cloud_url
   QDRANT_API_KEY=your_api_key
   HUGGINGFACE_API_KEY=your_hf_token
   ```

## ğŸ’¡ Quick Start (Local Development)

### ğŸ  Local with Ollama (Private)

1. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

2. **Setup Ollama**:
   ```bash
   # Install from https://ollama.ai
   ollama pull mistral:latest
   ollama serve
   ```

3. **Configure environment** (copy `.env.template` to `.env`):
   ```
   ENVIRONMENT=local
   QDRANT_URL=your_qdrant_cloud_url
   QDRANT_API_KEY=your_api_key
   ```

4. **Run**:
   ```bash
   streamlit run app.py
   ```

### â˜ï¸ Cloud Development

1. **Get HuggingFace token**: [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)
2. **Set environment**:
   ```
   ENVIRONMENT=production
   HUGGINGFACE_API_KEY=your_hf_token
   QDRANT_URL=your_qdrant_cloud_url
   QDRANT_API_KEY=your_api_key
   ```

## ğŸŒ Live Demo

- **HuggingFace Spaces**: [View Demo](#) *(Add your HF Spaces URL)*
- **Streamlit Cloud**: [View Demo](#) *(Add your Streamlit URL)*

## ğŸ”§ Features

- **ğŸ“„ Multi-format support**: PDF, TXT, DOCX
- **ğŸ” Semantic search**: Find relevant document sections
- **ğŸ’¬ Chat interface**: Natural conversation with your documents
- **ğŸ“ Source citations**: Know which documents provided answers
- **ğŸ”„ Environment switching**: Local privacy or cloud deployment
- **âš¡ Auto-sync**: GitHub â†’ HF Spaces deployment

## ğŸ“‚ Project Structure

```
rag-project/
â”œâ”€â”€ app.py              # Main Streamlit application
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ .env.template      # Environment variables template
â”œâ”€â”€ .streamlit/        # Streamlit configuration
â”œâ”€â”€ Procfile          # Deployment configuration
â””â”€â”€ README.md         # This file
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature-name`
3. Commit changes: `git commit -m 'Add feature'`
4. Push to branch: `git push origin feature-name`
5. Submit a pull request

## ğŸ“ License

MIT License - feel free to use for personal and commercial projects.

---

**ğŸ¯ Built for Portfolio Demonstration**

*Showcasing RAG architecture, vector databases, environment management, and modern AI integration with professional deployment workflows.*

**ğŸ”— Connect:**
- GitHub: [Your GitHub Profile](#)
- LinkedIn: [Your LinkedIn](#)
- Portfolio: [Your Portfolio Site](#)
